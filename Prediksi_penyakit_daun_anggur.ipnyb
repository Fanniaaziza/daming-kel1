import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping
import numpy as np
import os
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# 1. Parameter Dataset
IMAGE_SIZE = 224  # Ukuran gambar setelah resize
BATCH_SIZE = 32   # Ukuran batch
CLASSES = ['Black Rot', 'ESCA', 'Healthy', 'Leaf Blight']  # Nama kelas
train_dir = "/content/primer+sekunder/primer+sekunder/Train"

# 2. Preprocessing Data
def load_dataset(directory):
    return tf.keras.utils.image_dataset_from_directory(
        directory,
        shuffle=True,
        batch_size=BATCH_SIZE,
        image_size=(IMAGE_SIZE, IMAGE_SIZE)
    )

# Memuat dataset train dan test
train_ds = load_dataset(train_dir)
#test_ds = load_dataset(test_dir)

# Membagi dataset menjadi train, val, dan test
def dataset_partition(ds, train_split=0.8, val_split=0.1, shuffle=True, shuffle_size=1000):
    ds_size = len(ds)
    if shuffle:
        ds = ds.shuffle(shuffle_size, seed=8)

    train_size = int(ds_size * train_split)
    val_size = int(ds_size * val_split)

    train_ds = ds.take(train_size)
    val_ds = ds.skip(train_size).take(val_size)
    test_ds = ds.skip(train_size).skip(val_size)

    return train_ds, val_ds, test_ds

train_ds, val_ds, test_ds = dataset_partition(train_ds)

# Cache, shuffle, prefetch untuk mempercepat proses pelatihan
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)
test_ds = test_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)

# 3. Data Augmentation dan Rescaling
resize_and_rescale = tf.keras.Sequential([
    layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),
    layers.Rescaling(1.0 / 255)
])

data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal_and_vertical"),
    layers.RandomRotation(0.2)
])

# 4. Membuat Model CVNN
def create_cvnn_model(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), n_classes=len(CLASSES)):
    model = models.Sequential([
        layers.Input(shape=input_shape),  # Tambahkan lapisan Input di awal
        resize_and_rescale,
        data_augmentation,
        layers.Conv2D(32, (3, 3), activation="relu"),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation="relu"),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation="relu"),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(128, activation="relu"),
        layers.Dropout(0.5),  # Dropout untuk mengurangi overfitting
        layers.Dense(n_classes, activation="softmax")  # Output layer untuk klasifikasi multi-kelas
    ])
    return model

# Membuat model
model = create_cvnn_model()

# 5. Kompilasi Model
model.compile(
    optimizer="adam",
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=["accuracy"]
)

# 6. EarlyStopping untuk menghentikan pelatihan lebih awal jika tidak ada perbaikan pada akurasi validasi
early_stopping = EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)

# 7. Pelatihan Model
EPOCHS = 50
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    callbacks=[early_stopping]
)

# 8. Evaluasi Model
scores = model.evaluate(test_ds)
print(f"Test Loss: {scores[0]}")
print(f"Test Accuracy: {scores[1]}")

# 9. Visualisasi Confusion Matrix
def evaluate_and_visualize(model, test_ds):
    y_test = []
    y_pred = []
    for image_batch, label_batch in test_ds:
        y_test.extend(label_batch.numpy())
        preds = model.predict(image_batch)
        y_pred.extend(np.argmax(preds, axis=1))

    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=CLASSES, yticklabels=CLASSES)
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title("Confusion Matrix")
    plt.show()

    print("Classification Report:")
    print(classification_report(y_test, y_pred, target_names=CLASSES))

evaluate_and_visualize(model, test_ds)

# 10. Prediksi Individual
def predict(model, img_path):
    image = tf.keras.utils.load_img(img_path, target_size=(IMAGE_SIZE, IMAGE_SIZE))
    image_array = tf.keras.utils.img_to_array(image)
    image_array = tf.expand_dims(image_array, axis=0)  # Tambahkan dimensi batch
    image_array = image_array / 255.0  # Normalisasi

    prediction = model.predict(image_array)
    predicted_class = CLASSES[np.argmax(prediction)]
    confidence = round(100 * np.max(prediction), 2)
    return predicted_class, confidence

test_image_path = "/content/primer+sekunder/primer+sekunder/Train/Black Rot/003d09ef-e16c-4e8a-badf-847d46cb3dc0___FAM_B.Rot 3184_flipLR.JPG"
predicted_class, confidence = predict(model, test_image_path)
print(f"Prediksi: {predicted_class}, Kepercayaan: {confidence}%")
